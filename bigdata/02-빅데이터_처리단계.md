# 빅데이터 처리단계

빅데이터는 다음의 5단계로 처리된다.

1. 수집
    - 데이터를 수집하는 단계
    - 정형, 비정형, 반정형 데이터 수집
2. 정제
    - 수집한 데이터를 적재하기 위해 필요 없는 데이터, 깨진 데이터를 정리하는 단계
    - 반정형, 비정형 데이터는 분석에 필요한 데이터 외에 필요 없는 부분을 제거하는 단계가 필요
3. 적재
    - 정제된 데이터를 분석하기 위해 적재하는 단계
    - RDB, NoSQL 데이터베이스, Redshift, Druid 등의 도구에 적재
4. 분석
    - 적재한 데이터를 의미 있는 지표로 분석하는 단계
    - 의사결정권자나 이용자가 사용할 수 있는 데이터로 분석하는 단계
5. 시각화
    - 분석한 데이터를 도표로 보여주는 단계
    - 데이터를 이해하기 쉬운 차트로 분석하는 단계

## 수집

빅데이터는 내부/외부 여러 원천(Source)에서 데이터를 수집한다. 다양한 형식의 데이터를 수집한다.

### 데이터 수집 기술

- Flume
    - 많은 양의 로그 데이터를 효율적으로 수집, 취합, 이동하기 위한 분산형 소프트웨어
- **Kafka**
    - 오픈 소스 메시지 브로커 프로젝트
- Sqoop
    - 관계형 데이터 베이스와 아파치 하둡간의 대용량 데이터들을 효율적으로 변환 하여 주는 명령 줄 인터페이스 애플리케이션
- Nifi
    - 소프트웨어 시스템 간 데이터 흐름을 자동화하도록 설계된 소프트웨어 프로젝트
- **Flink**
    - 오픈 소스 스트림 처리 프레임 워크
- Splunk
    - 기계가 생성한 빅 데이터를, 웹 스타일 인터페이스를 통해 검색, 모니터링, 분석하는 소프트웨어
- **Logstash**
    - 실시간 파이프라인 기능을 가진 오픈소스 데이터 수집 엔진
- Fluentd
    - 크로스 플랫폼 오픈 소스 데이터 수집 소프트웨어 프로젝트

### 정제

정제 단계는 데이터를 분석 가능한 형태로 정리하는 것이다. 여러 경로에서 수집된 데이터의 형태가 모두 다르기 때문에 분석 단계에 사용할 도구에 맞는 형태로 변환한다. 데이터를 변환할 때 오류 데이터,
불필요한 데이터를 제거하고 정제한 데이터는 압축하여 데이터 사이즈를 줄인다.

### 적재

적재 단계는 대량의 데이터를 안전하게 보관하고 분석할 수 있는 환경으로 옮기는 것이다.

분석에 사용할 도구에 따라 RDB, NoSQL, 클라우드 스토리지, HDFS 등 다양한 환경으로 데이터를 적재한다. RDB에서 추출한 데이터나, CSV 형태로 제공되는 데이터는 별도의 정제 단계없이
바로 적재할 수 있다.

### 분석

분석 단계는 적재된 데이터를 이용하여 의사 결정을 위한 데이터를 제공하기 위한 리포트를 생성하는 단계이다.

대용량의 데이터를 빠르게 분석하기 위한 처리 엔진이 필요하고, 효율적으로 분석하기 위해서 파티셔닝, 인덱싱 등의 기술이 필요하다. 실시간 분석, 배치 분석(일, 주, 월단위)을 이용해 리포트를
생성한다.

### 시각화

너무 많은 데이터는 정보 과잉으로 사용자가 확인하기에 부담이 될 수 있기 때문에 사용자가 빠르게 인식할 수 있는 형태의 시각화가 필요하다.
